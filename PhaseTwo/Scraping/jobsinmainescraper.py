from wsgiref.util import application_uri

from bs4 import BeautifulSoup
import requests
import csv
from datetime import datetime, timedelta
import re

# Method generated with Sonnet 4.5 to convert given strings to time stamps
# e.g. "10h ago", "2d ago", "1w ago", "3m ago"
def parse_posted_time(posted_str):
    """
    Convert '10h ago', '2d ago', '1w ago' to a datetime timestamp
    """
    # Remove extra whitespace
    posted_str = posted_str.strip().lower()

    # Extract number and unit (h, d, w, m for month)
    match = re.match(r'(\d+)\s*([hdwm])', posted_str)

    if not match:
        return None

    amount = int(match.group(1))
    unit = match.group(2)

    # Get current time
    now = datetime.now()

    # Calculate the posted time
    if unit == 'h':  # hours
        posted_time = now - timedelta(hours=amount)
    elif unit == 'd':  # days
        posted_time = now - timedelta(days=amount)
    elif unit == 'w':  # weeks
        posted_time = now - timedelta(weeks=amount)
    elif unit == 'm':  # months (approximate as 30 days)
        posted_time = now - timedelta(days=amount * 30)
    else:
        return None

    return posted_time.replace(microsecond=0)

# Method generated by Sonnet 4.5 by this prompt: currently the salary is given as  $20 - $28 / hour or $57k - $65k / year with there sometimes being only one figure mentioned. I want to split that to min and max salary in the form of min sal:  xamount /hour or year and max sal: xamount / hour or year. Make a function that does this
def parse_salary(salary_str):
    """
    Parse salary string and return min, max, and period

    Examples:
        "$20 - $28 / hour" -> min: $20/hour, max: $28/hour
        "$57k - $65k / year" -> min: $57k/year, max: $65k/year
        "$50k / year" -> min: $50k/year, max: $50k/year (same)
    """
    if not salary_str:
        return None, None, None

    # Clean up the string
    salary_str = salary_str.strip()

    # Extract the period (hour, year, etc.)
    period_match = re.search(r'/(.*?)$', salary_str)
    period = period_match.group(1).strip() if period_match else None

    # Find all salary amounts (handles $20, $57k, $65k, etc.)
    amounts = re.findall(r'\$(\d+\.?\d*k?)', salary_str, re.IGNORECASE)

    if not amounts:
        return None, None, None

    # Format amounts back with $
    formatted_amounts = [f"${amt}" for amt in amounts]

    if len(formatted_amounts) == 1:
        # Only one salary mentioned - min and max are the same
        min_sal = f"{formatted_amounts[0]}/{period}" if period else formatted_amounts[0]
        max_sal = min_sal  # Same as min
    elif len(formatted_amounts) >= 2:
        # Range provided
        min_sal = f"{formatted_amounts[0]}/{period}" if period else formatted_amounts[0]
        max_sal = f"{formatted_amounts[1]}/{period}" if period else formatted_amounts[1]
    else:
        min_sal = None
        max_sal = None

    return min_sal, max_sal, period

csv_file = "maine_jobs.csv"
fieldnames = [
    "Job Title",
    "Employer Website",
    "Employer Name",
    "Location",
    "Min Salary",
    "Max Salary",
    "Posted At",
    "Application URL"
]

with open(csv_file, "w", newline="", encoding="utf-8") as f:
    writer = csv.DictWriter(f, fieldnames=fieldnames)
    writer.writeheader()


base_url = 'https://jobsinmaine.com/jobs'
page = requests.get(base_url)
soup = BeautifulSoup(page.text, 'html.parser')


for page_num in range(1, 5):
    if page_num == 1:
        url = base_url
    else:
        url = base_url + f'?page={page_num}'
    page = requests.get(url)
    temp = soup.find_all('a', attrs={'class': 'job-details-link'})

    if not temp:
        print(f"No jobs found on page {page_num}. Stopping.")
        break
    count = 0
    for link in temp:
        href = link['href']
        cleaned_href = href[5:]
        full_url = base_url + cleaned_href
        new_page = requests.get(full_url)
        soup2 = BeautifulSoup(new_page.text, 'html.parser')

        job_title = soup2.find('h1', class_='jb-color-0f172aff')
        if job_title:
            title_text = job_title.text.strip()
            print("Job Title: ",title_text)


        info_div = job_title.findNext('div').findNext('div', class_="d-flex align-items-center flex-wrap jb-gap-lg")
        tags = info_div.find_all(['a', 'span'])
        relevant_tags = [t for i, t in enumerate(tags, start=1) if i % 2 == 1]

        employer_website = ""
        title_text = ""
        employer_name = ""
        location = ""
        min_sal = ""
        max_sal = ""
        posted_at = ""
        application_url = ""


        if relevant_tags:
            company_link = relevant_tags[0].get('href')
            cleaned_url = base_url.removesuffix('/jobs')
            employer_website = cleaned_url + company_link if company_link else ""
            print("Employer Website: ", full_url)

        values = [t.get_text(strip=True) for t in relevant_tags]


        if len(values) == 4:
            employer_name = values[0]
            location = values[1]
            min_sal, max_sal, period = parse_salary(values[2])
            posted_at = parse_posted_time(values[3])
        if len(values) == 3:
            employer_name = values[0]
            location = values[1]
            posted_at = parse_posted_time(values[2])

        apply_link = soup2.find('a', id = "job-apply-btn")
        if apply_link:
            apply_url = apply_link['href']
            cleaned_href = href[5:]
            full_url = base_url + cleaned_href
            application_url = full_url

        writer.writerow({
            "Job Title": title_text,
            "Employer Website": employer_website,
            "Employer Name": employer_name,
            "Location": location,
            "Min Salary": min_sal,
            "Max Salary": max_sal,
            "Posted At": posted_at,
            "Application URL": application_url
        })

